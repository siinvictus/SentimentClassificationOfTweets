{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 3 - Pipeline 1 and Pipeline 2 with Prep 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from  sklearn.metrics  import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from  sklearn.metrics  import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bs4 import BeautifulSoup\n",
    "dev_df = pd.read_csv(\"C:/Users/LENOVO/Downloads/DSL2122_january_dataset/DSL2122_january_dataset/development.csv\")\n",
    "eval_df = pd.read_csv(\"C:/Users/LENOVO/Downloads/DSL2122_january_dataset/DSL2122_january_dataset/evaluation.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep 3 - using SnowBall Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORK ON DUPLICATES => remove the duplicates\n",
    "dev_df.drop_duplicates(subset = 'text', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns that we won't use\n",
    "dev_df.drop(['ids', 'date','flag', 'user'], axis=1, inplace=True)\n",
    "eval_df.drop(['ids', 'date','flag', 'user'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of a dictionary of negations that splits abbrevations onto their full format.\n",
    "#creation of the cleaner function in order to preprocess only the text feature of both development and evaluation set\n",
    "#the function itself handles the HTML decoding, the @, the URLs, the uppercase letters, the negations and tokenizes the tweets\n",
    "#eliminating the punctuations\n",
    "\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def cleaner(tweet):\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    \n",
    "    soup = BeautifulSoup(tweet, 'html.parser')\n",
    "    tweet = soup.get_text()\n",
    "    tweet = re.sub('@[A-Za-z0-9]+',\"\",tweet)\n",
    "    tweet = re.sub(r'https?://[^ ]+', \"\", tweet)\n",
    "    tweet = re.sub(r'www.[^ ]+', \"\", tweet)\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", \" \", tweet)\n",
    "    tweet_lower = tweet.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], tweet_lower)\n",
    "    \n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "    tweet_tokens = tokenizer.tokenize(neg_handled)\n",
    "\n",
    "\n",
    " \n",
    "    theTweet=''\n",
    "\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in string.punctuation):\n",
    "            stem_word = stemmer.stem(word)\n",
    "            theTweet= theTweet+ \" \" + stem_word\n",
    "    \n",
    "    return theTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \"Cookies \" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#cleaner function applied to the text column of the development dataset\n",
    "testing = dev_df.text\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaner function applied to the text column of the evaluation dataset\n",
    "eval_testing = eval_df.text\n",
    "eval_test_result = []\n",
    "for t in eval_testing:\n",
    "    eval_test_result.append(cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending the clean_text columns in both the development and evaluation dataframe\n",
    "dev_df['clean_text'] = test_result\n",
    "eval_df['clean_text'] = eval_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>@MissBianca76 Yes, talking helps a lot.. going...</td>\n",
       "      <td>yes talk help a lot go through it there s no ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SUNSHINE. livingg itttt. imma lie on the grass...</td>\n",
       "      <td>sunshin livingg ittt imma lie on the grass li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>@PleaseBeMine Something for your iphone</td>\n",
       "      <td>someth for your iphon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>@GabrielSaporta couldn't get in to the after p...</td>\n",
       "      <td>couldn t get in to the after parti</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@bradiewebbstack awww is andy being mean again...</td>\n",
       "      <td>a andi be mean again now i want macca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          1  @MissBianca76 Yes, talking helps a lot.. going...   \n",
       "1          1  SUNSHINE. livingg itttt. imma lie on the grass...   \n",
       "2          1           @PleaseBeMine Something for your iphone    \n",
       "3          0  @GabrielSaporta couldn't get in to the after p...   \n",
       "4          0  @bradiewebbstack awww is andy being mean again...   \n",
       "\n",
       "                                          clean_text  \n",
       "0   yes talk help a lot go through it there s no ...  \n",
       "1   sunshin livingg ittt imma lie on the grass li...  \n",
       "2                              someth for your iphon  \n",
       "3                 couldn t get in to the after parti  \n",
       "4              a andi be mean again now i want macca  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 1 (SGDClassifier algorithm) on Prep 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the dataset in training and test set fixing the test size of 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(dev_df['clean_text'], dev_df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt of the algorithm SGDClassifier without tuning the hyperparameters\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(eval_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputSGDprep3notuning.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "Best score: 0.802\n"
     ]
    }
   ],
   "source": [
    "#application of the GridSearchCV for finding the best combination of hyperparameters for all the three algorithms\n",
    "#CountVectorizer(max_df, max_features, ngram_range)\n",
    "#TfidfTransform (use_idf)\n",
    "#SGDClassifier (max_iter, alpha, penalty)\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    \"clf__loss\": ('hinge', 'log'),\n",
    "    \"clf__alpha\": (0.00001, 0.000001),\n",
    "    'clf__max_iter': (1000, 5000, 10000),\n",
    "}\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 1e-05\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__max_iter: 5000\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "#Printing the best combination of hyperparameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt of the SGDClassifier after the GridSearch\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.75, ngram_range=(1, 3), max_features=None)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', SGDClassifier(alpha=1e-05, max_iter=5000, loss='hinge')),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(eval_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputSGDprep3.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 2 (MultinomialNB algorithm) on Prep 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the dataset in training and test set fixing the test size of 0.01\n",
    "X_train, X_test, y_train, y_test = train_test_split(dev_df['clean_text'], dev_df['sentiment'], test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attempt of the MultinomialNB without hyperparameters tuning\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(eval_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputNBprep3notuning.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.782\n"
     ]
    }
   ],
   "source": [
    "#application of the GridSearchCV for finding the best combination of hyperparameters for all the three algorithms\n",
    "#CountVectorizer(max_df, ngram_range)\n",
    "#TfidfTransform\n",
    "#SGDClassifier (alpha)\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3)),\n",
    "    'clf__alpha': np.arange(0, 1, 0.05),\n",
    "}\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, cv=3)\n",
    "grid_search.fit(dev_df['clean_text'], dev_df['sentiment'])\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.25\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "#Printing the best combination of hyperparameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt of the MultinomialNB after the GridSearch\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2), max_df=0.5)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha=0.25)),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(eval_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputNBprep3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
