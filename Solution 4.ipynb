{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 4 - Pipeline 1 and 2 on Prep 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from  sklearn.metrics  import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from  sklearn.metrics  import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bs4 import BeautifulSoup\n",
    "dev_df = pd.read_csv(\"C:/Users/LENOVO/Downloads/DSL2122_january_dataset/DSL2122_january_dataset/development.csv\")\n",
    "eval_df = pd.read_csv(\"C:/Users/LENOVO/Downloads/DSL2122_january_dataset/DSL2122_january_dataset/evaluation.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing 4  - with user and date included, no stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORK ON DUPLICATES => remove the duplicates\n",
    "dev_df.drop_duplicates(subset = 'text', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that we won't use\n",
    "dev_df.drop(['ids','flag'], axis=1, inplace=True)\n",
    "eval_df.drop(['ids', 'flag'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of a dictionary of negations that splits abbrevations onto their full format\n",
    "#creation of the cleaner function in order to preprocess only the text feature of both development and evaluation set\n",
    "#the function itself handles the HTML decoding, the @, the URLs, the uppercase letters, the negations and tokenizes the tweets\n",
    "#eliminating the punctuations\n",
    "\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def cleaner(tweet):\n",
    "    \n",
    "    soup = BeautifulSoup(tweet, 'html.parser')\n",
    "    tweet = soup.get_text()\n",
    "    tweet = re.sub('@[A-Za-z0-9]+',\"\",tweet)\n",
    "    tweet = re.sub(r'https?://[^ ]+', \"\", tweet)\n",
    "    tweet = re.sub(r'www.[^ ]+', \"\", tweet)\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", \" \", tweet)\n",
    "    tweet_lower = tweet.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], tweet_lower)\n",
    "    \n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "    tweet_tokens = tokenizer.tokenize(neg_handled)\n",
    "\n",
    "\n",
    "    theTweet = ' '\n",
    "  \n",
    "\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in string.punctuation): \n",
    "            theTweet=theTweet+ ' '+word\n",
    "  \n",
    "    return theTweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\dateutil\\parser\\_parser.py:1213: UnknownTimezoneWarning: tzname PDT identified but not understood.  Pass `tzinfos` argument in order to correctly return a timezone-aware datetime.  In a future version, this will raise an exception.\n",
      "  warnings.warn(\"tzname {tzname} identified but not understood.  \"\n"
     ]
    }
   ],
   "source": [
    "#the attribute 'date' in both development set and evaluation set has type <object>\n",
    "#the pandas library transform the date object in datetime64[ns] which allows us to extrapolate the part of the datetime\n",
    "#that we require with the pre-defined pandas functions\n",
    "\n",
    "dev_df['date']=pd.to_datetime(dev_df['date'])\n",
    "eval_df['date']=pd.to_datetime(eval_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction only of the hour from the datetime which is in format (hour:min:sec)\n",
    "dev_df['date_hour']=dev_df['date'].dt.hour\n",
    "eval_df['date_hour']=eval_df['date'].dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction of the date in the format (year-month-day)\n",
    "dev_df['date']=dev_df['date'].dt.date\n",
    "eval_df['date']=eval_df['date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \"Cookies \" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#cleaner function applied to the text column of the development dataset\n",
    "testing = dev_df.text\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaner function applied to the text column of the evaluation dataset\n",
    "eval_testing = eval_df.text\n",
    "eval_test_result = []\n",
    "for t in eval_testing:\n",
    "    eval_test_result.append(cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending the clean_text columns in both the development and evaluation dataframe\n",
    "dev_df['clean_text'] = test_result\n",
    "eval_df['clean_text'] = eval_test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.drop(['text'], axis=1, inplace=True)\n",
    "eval_df.drop(['text'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of a new column merging the attributes: text, date, hour and user all in the string format\n",
    "dev_df['total'] = dev_df['date'].astype(str) + \" \" + dev_df['date_hour'].astype(str) + \" \" + dev_df['clean_text'] + \" \" + dev_df['user'].astype(str)\n",
    "eval_df['total'] = eval_df['date'].astype(str) + \" \" + eval_df['date_hour'].astype(str) + \" \" + eval_df['clean_text'] + \" \" + eval_df['user'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-05-18</td>\n",
       "      <td>Killandra</td>\n",
       "      <td>1</td>\n",
       "      <td>yes talking helps a lot going through it the...</td>\n",
       "      <td>2009-05-18 1   yes talking helps a lot going t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-05-31</td>\n",
       "      <td>IMlisacowan</td>\n",
       "      <td>6</td>\n",
       "      <td>sunshine livingg ittt imma lie on the grass ...</td>\n",
       "      <td>2009-05-31 6   sunshine livingg ittt imma lie ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>yaseminx3</td>\n",
       "      <td>11</td>\n",
       "      <td>something for your iphone</td>\n",
       "      <td>2009-06-01 11   something for your iphone yase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-05-17</td>\n",
       "      <td>no_surprises</td>\n",
       "      <td>2</td>\n",
       "      <td>couldn t get in to the after party</td>\n",
       "      <td>2009-05-17 2   couldn t get in to the after pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2009-06-02</td>\n",
       "      <td>Rhi_ShortStack</td>\n",
       "      <td>0</td>\n",
       "      <td>a andy being mean again now i want maccas</td>\n",
       "      <td>2009-06-02 0   a andy being mean again now i w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment        date            user  date_hour  \\\n",
       "0          1  2009-05-18       Killandra          1   \n",
       "1          1  2009-05-31     IMlisacowan          6   \n",
       "2          1  2009-06-01       yaseminx3         11   \n",
       "3          0  2009-05-17    no_surprises          2   \n",
       "4          0  2009-06-02  Rhi_ShortStack          0   \n",
       "\n",
       "                                          clean_text  \\\n",
       "0    yes talking helps a lot going through it the...   \n",
       "1    sunshine livingg ittt imma lie on the grass ...   \n",
       "2                          something for your iphone   \n",
       "3                 couldn t get in to the after party   \n",
       "4          a andy being mean again now i want maccas   \n",
       "\n",
       "                                               total  \n",
       "0  2009-05-18 1   yes talking helps a lot going t...  \n",
       "1  2009-05-31 6   sunshine livingg ittt imma lie ...  \n",
       "2  2009-06-01 11   something for your iphone yase...  \n",
       "3  2009-05-17 2   couldn t get in to the after pa...  \n",
       "4  2009-06-02 0   a andy being mean again now i w...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>date_hour</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-06-01</td>\n",
       "      <td>urbanperspectiv</td>\n",
       "      <td>21</td>\n",
       "      <td>i m pretty much the same in either world</td>\n",
       "      <td>2009-06-01 21   i m pretty much the same in ei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2009-05-17</td>\n",
       "      <td>therealsecret</td>\n",
       "      <td>11</td>\n",
       "      <td>same here have a gr week ahead</td>\n",
       "      <td>2009-05-17 11   same here have a gr week ahead...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2009-04-19</td>\n",
       "      <td>bitchville</td>\n",
       "      <td>23</td>\n",
       "      <td>that s just nightmares all over</td>\n",
       "      <td>2009-04-19 23   that s just nightmares all ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2009-06-16</td>\n",
       "      <td>epi_longo</td>\n",
       "      <td>0</td>\n",
       "      <td>ch c ph i i thi i h c th t qu</td>\n",
       "      <td>2009-06-16 0   ch c ph i i thi i h c th t qu e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2009-05-30</td>\n",
       "      <td>Curiosafmmb</td>\n",
       "      <td>12</td>\n",
       "      <td>sweetie awe ok sweetie ttyl hugs</td>\n",
       "      <td>2009-05-30 12   sweetie awe ok sweetie ttyl hu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date             user  date_hour  \\\n",
       "0  2009-06-01  urbanperspectiv         21   \n",
       "1  2009-05-17    therealsecret         11   \n",
       "2  2009-04-19       bitchville         23   \n",
       "3  2009-06-16        epi_longo          0   \n",
       "4  2009-05-30      Curiosafmmb         12   \n",
       "\n",
       "                                   clean_text  \\\n",
       "0    i m pretty much the same in either world   \n",
       "1              same here have a gr week ahead   \n",
       "2             that s just nightmares all over   \n",
       "3               ch c ph i i thi i h c th t qu   \n",
       "4            sweetie awe ok sweetie ttyl hugs   \n",
       "\n",
       "                                               total  \n",
       "0  2009-06-01 21   i m pretty much the same in ei...  \n",
       "1  2009-05-17 11   same here have a gr week ahead...  \n",
       "2  2009-04-19 23   that s just nightmares all ove...  \n",
       "3  2009-06-16 0   ch c ph i i thi i h c th t qu e...  \n",
       "4  2009-05-30 12   sweetie awe ok sweetie ttyl hu...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 1 (SGDClassifier algorithm) on Prep 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the dataset in training and test set fixing the test size of 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(dev_df['total'], dev_df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', SGDClassifier())])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attempt of the algorithm SGDClassifier without tuning the hyperparameters\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "text_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(eval_df['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputSGDprep4notuning.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "Best score: 0.846\n"
     ]
    }
   ],
   "source": [
    "#application of the GridSearchCV for finding the best combination of hyperparameters for all the three algorithms\n",
    "#CountVectorizer(max_df, max_features, ngram_range)\n",
    "#TfidfTransform (use_idf)\n",
    "#SGDClassifier (max_iter, alpha, penalty)\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    \"clf__loss\": ('hinge', 'log'),\n",
    "    \"clf__alpha\": (0.00001, 0.000001),\n",
    "    'clf__max_iter': (1000, 5000, 10000),\n",
    "}\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 1e-06\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__max_iter: 5000\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "#Printing the best combination of hyperparameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt of the SGDClassifier after the GridSearch\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.5, ngram_range=(1, 3), max_features=None)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', SGDClassifier(alpha=1e-06, max_iter=5000, loss='hinge')),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(eval_df['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputSGDprep4.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 2 (MultinomialNB algorithm) on Prep 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the dataset in training and test set fixing the test size of 0.01\n",
    "X_train, X_test, y_train, y_test = train_test_split(dev_df['total'], dev_df['sentiment'], test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attempt of the MultinomialNB without hyperparameters tuning\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(eval_df['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputNBprep4notuning.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.830\n"
     ]
    }
   ],
   "source": [
    "#application of the GridSearchCV for finding the best combination of hyperparameters for all the three algorithms\n",
    "#CountVectorizer(max_df, ngram_range)\n",
    "#TfidfTransform\n",
    "#SGDClassifier (alpha)\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3)),\n",
    "    'clf__alpha': np.arange(0, 1, 0.05),\n",
    "}\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, cv=3)\n",
    "grid_search.fit(dev_df['total'], dev_df['sentiment'])\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.15000000000000002\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "#Printing the best combination of hyperparameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt of the MultinomialNB after the GridSearch\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,3), max_df=0.5)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha=0.15000000000000002)),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(eval_df['total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputNBprep4.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
