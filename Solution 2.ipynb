{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solution 2 - Prep 2 combined with Pipeline 1 and Pipeline 2\n",
    "## The following code produces 2 CSV files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from  sklearn.metrics  import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from  sklearn.metrics  import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from bs4 import BeautifulSoup\n",
    "dev_df = pd.read_csv(\"C:/Users/LENOVO/Downloads/DSL2122_january_dataset/DSL2122_january_dataset/development.csv\")\n",
    "eval_df = pd.read_csv(\"C:/Users/LENOVO/Downloads/DSL2122_january_dataset/DSL2122_january_dataset/evaluation.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing 2 - using PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WORK ON DUPLICATES => remove the duplicates\n",
    "dev_df.drop_duplicates(subset = 'text', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop columns that we won't use\n",
    "dev_df.drop(['ids', 'date','flag', 'user'], axis=1, inplace=True)\n",
    "eval_df.drop(['ids', 'date','flag', 'user'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creation of a dictionary of negations that splits abbrevations onto their full format.\n",
    "#creation of the cleaner function in order to preprocess only the text feature of both development and evaluation set\n",
    "#the function itself handles the HTML decoding, the @, the URLs, the uppercase letters, the negations and tokenizes the tweets\n",
    "#eliminating the punctuations\n",
    "\n",
    "negations_dic = {\"isn't\":\"is not\", \"aren't\":\"are not\", \"wasn't\":\"was not\", \"weren't\":\"were not\",\n",
    "                \"haven't\":\"have not\",\"hasn't\":\"has not\",\"hadn't\":\"had not\",\"won't\":\"will not\",\n",
    "                \"wouldn't\":\"would not\", \"don't\":\"do not\", \"doesn't\":\"does not\",\"didn't\":\"did not\",\n",
    "                \"can't\":\"can not\",\"couldn't\":\"could not\",\"shouldn't\":\"should not\",\"mightn't\":\"might not\",\n",
    "                \"mustn't\":\"must not\"}\n",
    "\n",
    "neg_pattern = re.compile(r'\\b(' + '|'.join(negations_dic.keys()) + r')\\b')\n",
    "\n",
    "def cleaner(tweet):\n",
    "    \n",
    "    stemmer = PorterStemmer()\n",
    "    soup = BeautifulSoup(tweet, 'html.parser')\n",
    "    tweet = soup.get_text()\n",
    "    tweet = re.sub('@[A-Za-z0-9]+',\"\",tweet)\n",
    "    tweet = re.sub(r'https?://[^ ]+', \"\", tweet)\n",
    "    tweet = re.sub(r'www.[^ ]+', \"\", tweet)\n",
    "    tweet = re.sub(\"[^a-zA-Z]\", \" \", tweet)\n",
    "    tweet_lower = tweet.lower()\n",
    "    neg_handled = neg_pattern.sub(lambda x: negations_dic[x.group()], tweet_lower)\n",
    "    \n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=True)\n",
    "    tweet_tokens = tokenizer.tokenize(neg_handled)\n",
    "\n",
    "\n",
    " \n",
    "    theTweet=''\n",
    "\n",
    "    for word in tweet_tokens:\n",
    "        if (word not in string.punctuation):\n",
    "            stem_word = stemmer.stem(word)\n",
    "            theTweet= theTweet+ \" \" + stem_word\n",
    "    \n",
    "    return theTweet\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\anaconda3\\lib\\site-packages\\bs4\\__init__.py:332: MarkupResemblesLocatorWarning: \"Cookies \" looks like a filename, not markup. You should probably open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#cleaner function applied to the text column of the development dataset\n",
    "testing = dev_df.text\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaner function applied to the text column of the evaluation dataset\n",
    "eval_testing = eval_df.text\n",
    "eval_test_result = []\n",
    "for t in eval_testing:\n",
    "    eval_test_result.append(cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending the clean_text columns in both the development and evaluation dataframe\n",
    "dev_df['clean_text'] = test_result\n",
    "eval_df['clean_text'] = eval_test_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 2 (MultinomialNB algorithm) with Prep 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the dataset in training and test set fixing the test size of 0.01\n",
    "X_train, X_test, y_train, y_test = train_test_split(dev_df['clean_text'], dev_df['sentiment'], test_size=0.01, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vect', CountVectorizer()), ('tfidf', TfidfTransformer()),\n",
       "                ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#attempt with MultinomialNB without hyperparameters tuning\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = text_clf.predict(eval_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputNBprep2notuning.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.781\n"
     ]
    }
   ],
   "source": [
    "#application of the GridSearchCV for finding the best combination of hyperparameters for all the three algorithms\n",
    "#CountVectorizer(max_df, ngram_range)\n",
    "#TfidfTransform\n",
    "#SGDClassifier (alpha)\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3)),\n",
    "    'clf__alpha': np.arange(0, 1, 0.05),\n",
    "}\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, cv=3)\n",
    "grid_search.fit(dev_df['clean_text'], dev_df['sentiment'])\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.25\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n"
     ]
    }
   ],
   "source": [
    "#Printing the best combination of hyperparameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt of the MultinomialNB after the GridSearch\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(ngram_range=(1,2), max_df=0.5)),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB(alpha=0.25)),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(eval_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputNBprep2.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline 1 (SGDClassifier algorithm) with Prep 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting of the dataset in training and test set fixing the test size of 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(dev_df['clean_text'], dev_df['sentiment'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt of the algorithm SGDClassifier without tuning the hyperparameters\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(eval_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputSGDprep2notuning.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 864 candidates, totalling 4320 fits\n",
      "Best score: 0.802\n"
     ]
    }
   ],
   "source": [
    "#application of the GridSearchCV for finding the best combination of hyperparameters for all the three algorithms\n",
    "#CountVectorizer(max_df, max_features, ngram_range)\n",
    "#TfidfTransform (use_idf)\n",
    "#SGDClassifier (max_iter, alpha, penalty)\n",
    "\n",
    "parameters = {\n",
    "    \"vect__max_df\": (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 1), (1, 2), (1,3)),\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    \"clf__loss\": ('hinge', 'log'),\n",
    "    \"clf__alpha\": (0.00001, 0.000001),\n",
    "    'clf__max_iter': (1000, 5000, 10000),\n",
    "}\n",
    "\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', SGDClassifier()),\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(text_clf, parameters, n_jobs=-1, verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 1e-05\n",
      "\tclf__loss: 'hinge'\n",
      "\tclf__max_iter: 1000\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: None\n",
      "\tvect__ngram_range: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "#Printing the best combination of hyperparameters\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#attempt of the SGDClassifier after the GridSearch\n",
    "text_clf = Pipeline([\n",
    "    ('vect', CountVectorizer(max_df=0.75, ngram_range=(1, 3), max_features=None)),\n",
    "    ('tfidf', TfidfTransformer(use_idf=True)),\n",
    "    ('clf', SGDClassifier(alpha=1e-05, max_iter=1000, loss='hinge')),\n",
    "])\n",
    "text_clf.fit(X_train, y_train)\n",
    "predicted = text_clf.predict(eval_df['clean_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data= predicted, columns=['Predicted'])\n",
    "df.insert(0,'Id',df.index)\n",
    "df\n",
    "df.to_csv('C:/Users/LENOVO/Downloads/OutputSGDprep2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
